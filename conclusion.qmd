# Data
::: callout-note
## This page contains Tabs. Please click through tabs to see additional charts/info.
:::
## Description
For this project, we will be using a subset of the **Citywide Payroll Data**.\
This dataset is available via NYC OpenData and provided by the Office of Payroll Administration (OPA).

The final subset of data for this project will be focused on 2 Agencies:\
<p style="margin-top: -15px">
-   Fire Department üßë‚Äçüöí üöí
-   Police Department üëÆüöì
</p>

Here are the filters applied to the original data to produce our final subset of data:
```{r}
#| echo: false
#| message: false
#| warning: false


library(tibble)
library(knitr)
library(kableExtra)

payroll_data_format <- tibble(
  column_name = c(
    "Fiscal Year", 
    "Agency Name", 
    "Work Location Borough",
    "Pay Basis"
  ),
  filter = c(
    "From 2015 to 2024 (10 years)", 
    "FIRE DEPARTMENT, POLICE DEPARTMENT",
    "BRONX, BROOKLYN, MANHATTAN, QUEENS, STATEN ISLAND",
    "per Annum, per Day, per Hour"
  )
)

names(payroll_data_format) <- c("Column Name","Filter")

kable(payroll_data_format,
      # caption = "Dataset Format", 
      align = "l") |>
  kable_styling(full_width = FALSE) |>
  column_spec(1, width = "200px")
```

\

<!-- First, we will examine the metadata of the dataset, how to import the data and process the subset data. Finally, an analysis of missing values to identify any potential issues that may impact our analysis. -->

<!-- , followed by the decision-making process for selecting a subset of the data and transforming the original dataset with 6,225,611 rows to our final dataset with 804,630 rows. -->

```{r}
#| echo: false

rm(list = ls())
```

```{r}
#| echo: false
#| message: false
#| warning: false

# Import Libraries
library(tibble)
library(knitr)
library(kableExtra)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(visdat)
library(HH)
library(lubridate)
```

\
\



### Data information

The payroll data is provided annually by [NYC OpenData](https://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/about_data) and contains New York City employee salaries by Fiscal Year. We are using the latest snapshot of the data, released on October 30, 2024. Here are some details about the format of the data, the frequency of updates, dimensions about the data, and other relevant metadata:

::: panel-tabset
## Data Metadata

```{r}
#| echo: false


library(tibble)
library(knitr)
library(kableExtra)

# Create a tibble for the metadata
metadata <- tibble::tibble(
  Field = c(
    "Dataset Name",
    "Provided by",
    "Data Category",
    "Frequency of Updates ", 
    "Date Created", 
    "Data Last Updated", 
    "Dimensions",
    "Each row represents",
    "Source URL"
  ),
  Value = c(
    "Citywide Payroll Data (Fiscal Year)",
    "Office of Payroll Administration (OPA)",
    "City Government",
    "Annually", 
    "October 31, 2015", 
    "October 30, 2024", 
    "Raw Data: 6,225,611 rows | 17 columns <br> \n Subset Data: 804,630 rows | 17 columns",
    "City Employee Salary per Fiscal Year",
    "https://data.cityofnewyork.us/"
  )
)

# Print the metadata table using kable
kable(metadata, 
      col.names = NULL, 
      escape = F,
      format = "html",
      # caption = "Dataset Metadata",
      align = "l")  |>
  column_spec(1, width = "200px") |>
  kable_styling()

```

\
\

## Data Format

```{r}
#| echo: false



payroll_data_format <- tibble(
  column_name = c(
    "Fiscal Year", "Payroll Number", "Agency Name", "Last Name", "First Name", 
    "Mid Init", "Agency Start Date", "Work Location Borough", 
    "Title Description", "Leave Status as of June 30", "Base Salary", 
    "Pay Basis", "Regular Hours", "Regular Gross Paid", "OT Hours", 
    "Total OT Paid", "Total Other Pay"
  ),
  description = c(
    "Fiscal Year", "Payroll Number", "The Payroll agency that the employee works for", 
    "Last name of employee", "First name of employee", 
    "Middle initial of employee", "Date which employee began working for their current agency", 
    "Borough of employee's primary work location", "Civil service title description of the employee", 
    "Status of employee as of the close of the relevant fiscal year: Active, Ceased, or On Leave", 
    "Base Salary assigned to the employee", 
    "Lists whether the employee is paid on an hourly, per diem or annual basis", 
    "Number of regular hours employee worked in the fiscal year", 
    "The amount paid to the employee for base salary during the fiscal year", 
    "Overtime Hours worked by employee in the fiscal year", 
    "Total overtime pay paid to the employee in the fiscal year", 
    "Includes any compensation in addition to gross salary and overtime pay, i.e., Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable."
  ),
  # api_field_name = c(
  #   "fiscal_year", "payroll_number", "agency_name", "last_name", "first_name", 
  #   "mid_init", "agency_start_date", "work_location_borough", 
  #   "title_description", "leave_status_as_of_june_30", "base_salary", 
  #   "pay_basis", "regular_hours", "regular_gross_paid", "ot_hours", 
  #   "total_ot_paid", "total_other_pay"
  # ),
  data_type = c(
    "Number", "Number", "Text", "Text", "Text", 
    "Text", "Timestamp", "Text", 
    "Text", "Text", "Number", 
    "Text", "Number", "Number", "Number", 
    "Number", "Number"
  )
)

names(payroll_data_format) <- c("Column Name","Description","Data Type")

kable(payroll_data_format,
      # caption = "Dataset Format", 
      align = "l") |>
  kable_styling(full_width = FALSE) |>
  column_spec(1, width = "200px")
```

:::

\


### Data Source


```{mermaid}
%%| echo: false

flowchart LR
  A[Importing Data] --> B[Understanding and \n cleaning the raw data]
  B --> C(Transforming columns)
  B --> D(Filtering Data)
  B --> E(Backfilling NA)
  C --> F[Saving Subset Data]
  D --> F[Saving Subset Data]
  E --> F[Saving Subset Data]
```





::: panel-tabset
## **Importing the data**\

To access the data, we can go directly to the URL:\
<p style="font-size:95%; font-style:italic">
<https://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/about_data>
</p>

From this URL, you can click the button 'Export', and then select Download File-CSV format (All data 6225611 rows). This will download a file of about 840MB. Remember, we are using the data Last Updated on October 30, 2024.

The file will be downloaded with the name: Citywide_Payroll_Data\_\_Fiscal_Year\_\_**YYYYMMDD**.csv\
<p style="font-size:90%; font-style:italic">
(YYYYMMDD refers to the date that you downloaded the file)
</p>

Once the data was downloaded, it was added to a new folder inside the repository called 'data_source'.

```{r, eval=FALSE}
#| message: false
#| warning: false

# import original data
payroll_data_source <- read.csv("./data_source/Citywide_Payroll_Data__Fiscal_Year__20241111.csv")

# make a copy of original data for transformations
payroll_data <- data.frame(payroll_data_source)

# rename columns
names(payroll_data) <- gsub("[\\.]+", "_", tolower(names(payroll_data_source)))
```


\
\

## **Cleaning the data**\

The decision-making process for selecting a subset of the data and the detailed transformation and clean up of the original dataset with 6,225,611 rows to our final dataset with 804,630 rows can be found in the `Appendix` section.


\
\

## **Creating the final subset data**\

The data used for this analysis is a subset of the entire raw data. The **final subset data** (focused on the **Fire and Police departments**) contains 804,630 rows out of the 6,225,611 rows from the original dataset. 

To generate the final subset that will be used in the analysis, please run the code below:

```{r, eval=FALSE}
# `payroll_data` dataframe comes from the **Importing the data** section.

payroll_data_fire_police <-
  payroll_data |>
  # clean agency name:
  mutate(agency_name_clean = trimws(gsub("#\\d+$", "", agency_name))) |>
  # clean job titles:
  mutate(title_description = toupper(title_description)) |> 
  # clean location name:
  mutate(work_location_borough_clean = toupper(work_location_borough)) |>

  # filtering data:
  filter(agency_name_clean %in%  c("POLICE DEPARTMENT","FIRE DEPARTMENT")) |>
  filter(work_location_borough_clean %in%   c("BRONX", "BROOKLYN", "MANHATTAN", "QUEENS", "RICHMOND")) |>
  filter(fiscal_year >= "2015" & fiscal_year <= "2024") |>
  filter(pay_basis %in%   c("per Annum", "per Day", "per Hour")) |>

  # backfill payroll number after filtering
  mutate(
    payroll_number_clean = case_when(
      is.na(payroll_number) & agency_name_clean == "FIRE DEPARTMENT" ~ 57,
      is.na(payroll_number) & agency_name_clean == "POLICE DEPARTMENT" ~ 56,
      TRUE ~ payroll_number
    )) |>

  # converting dates:
  mutate(agency_start_date_clean = mdy(agency_start_date)) |>

  # renaming clean columns to original names:
  mutate(
    agency_name = agency_name_clean,
    work_location_borough = work_location_borough_clean,
    payroll_number = payroll_number_clean,
    agency_start_date = agency_start_date_clean
  ) |>

  # dropping clean columns
  dplyr::select(-agency_name_clean,
                -work_location_borough_clean,
                -payroll_number_clean,
                -agency_start_date_clean)



# Please uncomment the CSV or the RDS method to save the subset data:

# Save the data CSV
# write.csv(payroll_data_fire_police, "data_source/payroll_data_fire_police.csv", row.names = FALSE)

# Save the data RDS
# saveRDS(payroll_data_fire_police, "data_source/payroll_data_fire_police.rds")

# Read the data RDS
# payroll_data_fire_police <- readRDS("data_source/payroll_data_fire_police.rds")
```


:::

\
\





# Conclusion

The analysis of payroll data for NYC‚Äôs Fire and Police Departments highlights notable differences in employee distribution and compensation patterns. While the Police Department employs three times as many staff as the Fire Department, its total salary expenditure is only 2.5 times higher, suggesting that Fire Department employees, on average, receive higher pay.

Employment and salary trends also vary by location, with Manhattan hosting the majority of Police employees and Brooklyn leading in Fire Department staff. Salary progression aligns closely with years of experience, with employees earning higher compensation as their tenure increases. Among those earning over \$250K, the compensation structure varies significantly, with Overtime and Other pay contributing substantially to total earnings.

Future research should revisit the Police Department‚Äôs compensation for 2024, which shows an unusually high surge in total salaries. This anomaly appears inconsistent with the 2024 budget plans provided by the New York City Council and warrants deeper investigation.

<!-- ::: callout-note -->

<!-- 5 Conclusion  conclusion.qmd -->

<!-- Discuss: main takeaways of your exploration, limitations, future directions, lessons learned. -->

<!-- (suggested length: one paragraph) -->

<!-- ::: -->

------------------------------------------------------------------------

::: panel-tabset
## Original VS Subset Comparison


::: callout-note
## Diverging stacked bar chart to analyze missing data
[In this dataset, values classified as "Complete" or "Zero" are considered positive, as they indicate usable data that can be effectively analyzed. Conversely, "NA" and "Blank" values pose potential issues for data interpretation. To reflect this distinction, the diverging stacked bar chart will position "NA" and "Blank" values on the left side, representing a negative impact on the analysis.]{style="font-size:70%;"}
:::

::: callout-note
## Diverging stacked bar chart to analyze missing data
[In this dataset, values classified as "Complete" or "Zero" are considered positive, as they indicate usable data that can be effectively analyzed. Conversely, "NA" and "Blank" values pose potential issues for data interpretation. To reflect this distinction, the diverging stacked bar chart will position "NA" and "Blank" values on the left side, representing a negative impact on the analysis.]{style="font-size:82%;"}
:::

::: callout-note
## Diverging stacked bar chart to analyze missing data
[In this dataset, values classified as "Complete" or "Zero" are considered positive, as they indicate usable data that can be effectively analyzed. Conversely, "NA" and "Blank" values pose potential issues for data interpretation. To reflect this distinction, the diverging stacked bar chart will position "NA" and "Blank" values on the left side, representing a negative impact on the analysis.]{style="font-size:90%;"}
:::

::: callout-note
## Diverging stacked bar chart to analyze missing data
[In this dataset, values classified as "Complete" or "Zero" are considered positive, as they indicate usable data that can be effectively analyzed. Conversely, "NA" and "Blank" values pose potential issues for data interpretation. To reflect this distinction, the diverging stacked bar chart will position "NA" and "Blank" values on the left side, representing a negative impact on the analysis.]{style="font-size:60%;"}
:::

:::