[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fire and Police Department Payroll",
    "section": "",
    "text": "1 Introduction\nMy experience in the financial industry has fostered a strong interest in working with high-volume salary datasets.\nFor this project, I will analyze 10 years of payroll data for the Fire and Police departments in New York City. This dataset represents a well-defined and comprehensive universe of information, making it ideal for thorough exploration and analysis.\nOne of the reasons I selected this dataset is its versatility; it includes a variety of data types such as categorical text with differing levels of granularity, numerical data, dates, and fields with missing or outlier values. These characteristics provide opportunities to practice a range of analytical techniques, from data cleaning to advanced visualizations for pattern discovery.\nSpecifically, I am interested in studying trends such as workforce growth, salary composition across different roles, and identifying the top-ranking positions and locations with the highest payroll activity. By delving into these questions, I aim to uncover meaningful insights into the structure and evolution of these essential public service departments. Let‚Äôs uncover the stories hidden in the data!\nüöí üíµ üöì",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2¬† Data",
    "section": "",
    "text": "2.1 Description\nData Metadata\nDataset Name\nCitywide Payroll Data (Fiscal Year)\n\n\nProvided by\nOffice of Payroll Administration (OPA)\n\n\nData Category\nCity Government\n\n\nFrequency of Updates\nAnnually\n\n\nDate Created\nOctober 31, 2015\n\n\nData Last Updated\nOctober 30, 2024\n\n\nDimensions\nRaw Data: 6,225,611 rows | 17 columns\nSubset Data: 804,630 rows | 17 columns\n\n\nEach row represents\nCity Employee Salary per Fiscal Year\n\n\nSource URL\nhttps://data.cityofnewyork.us/\nData Format\nColumn Name\nDescription\nData Type\n\n\n\n\nFiscal Year\nFiscal Year\nNumber\n\n\nPayroll Number\nPayroll Number\nNumber\n\n\nAgency Name\nThe Payroll agency that the employee works for\nText\n\n\nLast Name\nLast name of employee\nText\n\n\nFirst Name\nFirst name of employee\nText\n\n\nMid Init\nMiddle initial of employee\nText\n\n\nAgency Start Date\nDate which employee began working for their current agency\nTimestamp\n\n\nWork Location Borough\nBorough of employee's primary work location\nText\n\n\nTitle Description\nCivil service title description of the employee\nText\n\n\nLeave Status as of June 30\nStatus of employee as of the close of the relevant fiscal year: Active, Ceased, or On Leave\nText\n\n\nBase Salary\nBase Salary assigned to the employee\nNumber\n\n\nPay Basis\nLists whether the employee is paid on an hourly, per diem or annual basis\nText\n\n\nRegular Hours\nNumber of regular hours employee worked in the fiscal year\nNumber\n\n\nRegular Gross Paid\nThe amount paid to the employee for base salary during the fiscal year\nNumber\n\n\nOT Hours\nOvertime Hours worked by employee in the fiscal year\nNumber\n\n\nTotal OT Paid\nTotal overtime pay paid to the employee in the fiscal year\nNumber\n\n\nTotal Other Pay\nIncludes any compensation in addition to gross salary and overtime pay, i.e., Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable.\nNumber\nImporting the data\nhttps://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/about_data\nFrom this URL, you can click the button ‚ÄòExport‚Äô, and then select Download File-CSV format (All data 6225611 rows). This will download a file of about 840MB. Remember, we are using the data Last Updated on October 30, 2024.\n(YYYYMMDD refers to the date that you downloaded the file)\nOnce the data was downloaded, it was added to a new folder inside the repository called ‚Äòdata_source‚Äô.\nCode\n# import original data\npayroll_data_source &lt;- read.csv(\"./data_source/Citywide_Payroll_Data__Fiscal_Year__20241111.csv\") \n\n# make a copy of original data for transformations\npayroll_data &lt;- data.frame(payroll_data_source)\n\n# rename columns\nnames(payroll_data) &lt;- gsub(\"[\\\\.]+\", \"_\", tolower(names(payroll_data_source)))\nCreating the final subset data\nThe decision-making process for selecting a subset of the data and the detailed transformation the original dataset with 6,225,611 rows to our final dataset with 804,630 rows.\nTo generate the final subset use the code below:\nCode\npayroll_data_fire_police &lt;-\n  payroll_data |&gt; \n  # clean agency name: \n  mutate(agency_name_clean = trimws(gsub(\"#\\\\d+$\", \"\", agency_name))) |&gt; \n  # clean location name: \n  mutate(work_location_borough_clean = toupper(work_location_borough)) |&gt; \n\n  # filtering data:\n  filter(agency_name_clean %in%  c(\"POLICE DEPARTMENT\",\"FIRE DEPARTMENT\")) |&gt; \n  filter(work_location_borough_clean %in%   c(\"BRONX\", \"BROOKLYN\", \"MANHATTAN\", \"QUEENS\", \"RICHMOND\")) |&gt; \n  filter(fiscal_year &gt;= \"2015\" & fiscal_year &lt;= \"2024\") |&gt; \n  filter(pay_basis %in%   c(\"per Annum\", \"per Day\", \"per Hour\")) |&gt; \n  \n  # backfill payroll number after filtering\n  mutate(\n    payroll_number_clean = case_when(\n      is.na(payroll_number) & agency_name_clean == \"FIRE DEPARTMENT\" ~ 57,\n      is.na(payroll_number) & agency_name_clean == \"POLICE DEPARTMENT\" ~ 56,\n      TRUE ~ payroll_number\n    )) |&gt; \n  \n  # converting dates:\n  mutate(agency_start_date_clean = mdy(agency_start_date)) |&gt; \n\n  # renaming clean columns to original names:\n  mutate(\n    agency_name = agency_name_clean,\n    work_location_borough = work_location_borough_clean,\n    payroll_number = payroll_number_clean,\n    agency_start_date = agency_start_date_clean\n  ) |&gt;\n  \n  # dropping clean columns\n  dplyr::select(-agency_name_clean, \n                -work_location_borough_clean, \n                -payroll_number_clean,\n                -agency_start_date_clean)\n  \n\n\n# Please uncomment the CSV or the RDS method to save the subset data:\n\n# Save the data CSV\n# write.csv(payroll_data_fire_police, \"data_source/payroll_data_fire_police.csv\", row.names = FALSE)\n\n# Save the data RDS\n# saveRDS(payroll_data_fire_police, \"data_source/payroll_data_fire_police.rds\")\n\n# Read the data RDS\n# payroll_data_fire_police &lt;- readRDS(\"data_source/payroll_data_fire_police.rds\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2¬† Data",
    "section": "",
    "text": "To access the data, we can go directly to the URL:\n\n\n\nThe file will be downloaded with the name: Citywide_Payroll_Data__Fiscal_Year__YYYYMMDD.csv",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2¬† Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\nTo analyse missing data, we will classify our data in 4 categories:\n¬†¬†¬† ‚ñ† NA - any values equal to NA\n¬†¬†¬† ‚ñ† Blank - string values equal to ‚Äú‚Äù\n¬†¬†¬† ‚ñ† Zero - numeric values equal to 0\n¬†¬†¬† ‚ñ† Present - any values with data\n\nFirst, let‚Äôs check the missing values of the original dataset.\nUsing a sample of 1 million records (from 6.22 million rows) we have close to 4.5% of missing data classified as NA or Blank by the vis_miss() plot. We can also observe missing values in 7 columns*:\n\n\n\n3 columns related to a person‚Äôs name (first_name, mid_init, last_name)\npayroll_number\nwork_location_borough\ntitle_description\nagency_start_date\n\n\n\n(*based on the black highlights and the percentages listed in the column names)\n\n\nCode\npayroll_data_missing &lt;- \n  payroll_data |&gt;\n  sample_n(100000) |&gt;\n  mutate(across(everything(), ~ if_else(. == \"\", NA, .)))\n\npayroll_data_missing |&gt; \n  vis_miss(\n    sort_miss = TRUE,\n    # cluster = TRUE,\n    show_perc_col = TRUE,\n    warn_large_data = FALSE,\n    ) + \n  ggtitle(\"Missing Values (NA or Blank) - Original Data Sample\")+\n  theme(plot.margin = margin(r = 50))\n\n\n\n\n\n\n\n\n\n\nAfter transforming our original data to create our final subset data (Fire and Police Departments), we can now examine how the missing values from the original compares to the final dataset.\n\n\nCode\n#Data Transformation\n\npayroll_data_total_summary &lt;- payroll_data |&gt;\n  summarise(across(everything(), ~ n())) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Total Count\"\n  )\n\npayroll_data_na_summary &lt;- payroll_data |&gt;\n  summarise(across(everything(), ~ sum(is.na(.)))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"NA\"\n  )\n\npayroll_data_blank_summary &lt;- payroll_data |&gt;\n  summarise(across(everything(), ~ sum(. == \"\", na.rm = TRUE))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Blank\"\n  )\n\npayroll_data_zero_summary &lt;- payroll_data |&gt;\n  summarise(across(everything(), ~ sum(. == 0, na.rm = TRUE))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Zero\"\n  )\n\npayroll_data_combined_summary &lt;- \n  payroll_data_total_summary |&gt; \n  inner_join(payroll_data_na_summary, by = \"Column\") |&gt; \n  inner_join(payroll_data_blank_summary, by = \"Column\") |&gt; \n  inner_join(payroll_data_zero_summary, by = \"Column\")\n\n\n# payroll_data_combined_summary\n\npayroll_data_combined_summary_likert &lt;-\npayroll_data_combined_summary |&gt; \n  mutate(`Present` = `Total Count` - `NA` - `Blank` - Zero) |&gt; \n  mutate(`Present` = `Present` / `Total Count`) |&gt; \n  mutate(`NA` = `NA` / `Total Count`) |&gt; \n  mutate(`Blank` = `Blank` / `Total Count`) |&gt; \n  mutate(`Zero` = Zero / `Total Count`) |&gt; \n  dplyr::select(`Column`,`NA`,`Blank`,Zero,`Present`) |&gt; \n  filter(!Column %in% c('agency_name_clean','work_location_borough_clean'))\n\n\nlikert_colors &lt;- c(\"NA\" = \"#D7191C\",\n                   \"Blank\" = \"#FDAE61\",\n                   \"Zero\" = \"#ABD9E9\",\n                   \"Present\" = \"#2C7BB6\")\n\n\n\npayroll_data_fire_police &lt;- readRDS(\"data_source/payroll_data_fire_police.rds\")\n\npayroll_data_fire_police_total_summary &lt;- payroll_data_fire_police |&gt;\n  summarise(across(everything(), ~ n())) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Total Count\"\n  )\n\npayroll_data_fire_police_na_summary &lt;- payroll_data_fire_police |&gt;\n  summarise(across(everything(), ~ sum(is.na(.)))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"NA\"\n  )\n\npayroll_data_fire_police_blank_summary &lt;- payroll_data_fire_police |&gt;\n  summarise(across(everything(), ~ sum(. == \"\", na.rm = TRUE))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Blank\"\n  )\n\npayroll_data_fire_police_zero_summary &lt;- payroll_data_fire_police |&gt;\n  summarise(across(everything(), ~ sum(. == 0, na.rm = TRUE))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Zero\"\n  )\n\n\npayroll_data_fire_police_combined_summary &lt;- \n  payroll_data_fire_police_total_summary |&gt; \n  inner_join(payroll_data_fire_police_na_summary, by = \"Column\") |&gt; \n  inner_join(payroll_data_fire_police_blank_summary, by = \"Column\") |&gt; \n  inner_join(payroll_data_fire_police_zero_summary, by = \"Column\")\n\n\npayroll_data_fire_police_combined_summary_likert &lt;-\n  payroll_data_fire_police_combined_summary |&gt; \n  mutate(`Present` = `Total Count` - `NA` - `Blank` - Zero) |&gt; \n  mutate(`Present` = `Present` / `Total Count`) |&gt; \n  mutate(`NA` = `NA` / `Total Count`) |&gt; \n  mutate(`Blank` = `Blank` / `Total Count`) |&gt; \n  mutate(`Zero` = Zero / `Total Count`) |&gt; \n  dplyr::select(`Column`,`NA`,`Blank`,Zero,`Present`) |&gt; \n  filter(!Column %in% c('agency_name_clean','work_location_borough_clean'))\n\n\n\n\nCode\npayroll_data_missing_group_likert &lt;- bind_rows(\n  payroll_data_combined_summary_likert |&gt; mutate(group= 'Original Data'), \n  payroll_data_fire_police_combined_summary_likert |&gt; mutate(group= 'Final Subset Data')\n)\n\nHH::likert(x=Column~. | group,payroll_data_missing_group_likert, \n           positive.order=TRUE,\n           as.percent = T,\n           main = 'Missing Value Analysis',\n           xlab='Percentage',\n           ylab='Columns',\n           col = likert_colors,\n           ReferenceZero=2.5,\n           rightAxis=FALSE,\n           # xlimEqualLeftRight=TRUE,\n           xlim=c(-50,100),\n           )\n\n\n\n\n\n\n\n\n\nOur original dataset has ‚ñ† NA data for payroll_number, first_name, last_name. It also has ‚ñ† Blank data in 6 columns: first_name, mid_init, last_name, work_location_borough, title_description, agency_start_date.\nFor both datasets, ‚ñ† Zero values show up in columns related to the amount paid to a person, which can be 3 categories: regular, overtime, other. If a certain category is 0, it means the person did not receive any money for that category. This in an important information because it does not requires us to exclude or impute these values. We can observe a significant reduction of zero values in the subset dataset compared to the original.\nOur final subset data (Fire and Police Departments) no longer contains ‚ñ† NA data, but still contains ‚ñ† Blank data in 3 columns: first_name, mid_init, last_name.\nFor mid_init (Middle Name Initials), 29% of the data in the final subset is Blank, it is ok for us to have blanks in the data, this will not affect the future analysis. For first_name and last_name blank data (1.2% of the data in the final subset is Blank), these values are blank on purpose by the data provider:\n‚Ä¶As a part of FISA-OPA‚Äôs routine process for reviewing and releasing Citywide Payroll Data, data for some agencies (specifically NYC Police Department (NYPD) and the District Attorneys‚Äô Offices (Manhattan, Kings, Queens, Richmond, Bronx, and Special Narcotics)) have been redacted since they are exempt from disclosure pursuant to the Freedom of Information Law, POL ¬ß 87(2)(f), on the ground that disclosure of the information could endanger the life and safety of the public servants listed thereon‚Ä¶\nBased on this disclosure, we can confirm the Blank values for the names are part of the Police Department agency:\n\n\nCode\npayroll_data_fire_police |&gt; \n  filter(first_name == \"\" | last_name == \"\") |&gt; \n  group_by(agency_name) |&gt; \n  summarise(`Count of Blank Records` = n()) |&gt; \n  kable(col.names = c(\"Agency\", \"Count of Blank Records\")) \n\n\n\n\n\nAgency\nCount of Blank Records\n\n\n\n\nPOLICE DEPARTMENT\n9992",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3¬† Results",
    "section": "",
    "text": "3.1 hitogram / facets (ps1)\nCode\nggplot(payroll_data_fire_police) +\n  geom_histogram(mapping = aes(x = total_paid, \n                               y = after_stat(density), \n                               fill = \"Density Histogram\"),\n                 binwidth = 10000,\n                 color = \"blue\",\n                 linetype = \"solid\",\n                 # center = 100000,\n                 # boundary = c(-50000,10000),\n                 # bo==\n                 )+\n  geom_density(mapping = aes(x = total_paid, \n                             color = \"Density Curve\"),\n               lwd = 1.2,\n               key_glyph = draw_key_path\n               ) +\n  geom_function(fun = dnorm,\n                aes(x = total_paid, \n                    color = \"Normal Curve\"), \n                lwd= 1.2,\n                args = list(mean = mean(payroll_data_fire_police$total_paid, na.rm = TRUE),\n                            sd = sd(payroll_data_fire_police$total_paid, na.rm = TRUE)),\n                ) +\n  scale_color_manual(values = c(\"Density Curve\" = \"red\", \"Normal Curve\" = \"limegreen\")) +\n  scale_fill_manual(values = c(\"Density Histogram\" = \"lightblue\")) +\n  scale_x_continuous(\n    limits = c(-25000, 300000),\n    breaks = seq(-50000, max(payroll_data_fire_police$total_paid, na.rm = TRUE), by = 25000),\n    labels = scales::label_number(scale = 1/1000, suffix = \"k\")\n  ) +\n  labs(title = \"Density Histogram of Room and Board Expenses\",\n       x = \"Room and Board Expenses\",\n       y = \"Density\",\n       color = \"Curves\",\n       fill = \"Bars\", \n       caption = \"Blue: Histogram, Red: Data Density Curve, Green: Normal Curve\") +\n  theme(legend.position = \"top\")\n\n\nWarning: Removed 439 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 439 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4¬† Interactive graph",
    "section": "",
    "text": "Temporal force-directed graph\n\n\n\n\nhi this is a test2wss\n\nsomething to go right below2\n\n\n\n\njan 15 balance october 16 nov 2015 red july 18 red March 2022 blue july 2020 blue\n\n\nsomething1\n\nAdd bar Remove bar\n\n\n\nsomething2\n\nAdd bar Remove bar\n\n\nsomething to go right below2\n\nanother this there",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Interactive graph</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "5¬† Conclusion",
    "section": "",
    "text": "hi, this is my conclusion\n\n\nCode\n# this is test\n\n\n\n\nCode\nflowchart LR\n  A[Importing Data] --&gt; B[Understanding and \\n cleaning the raw data]\n  B --&gt; C(Transforming columns)\n  B --&gt; D(Filtering Data)\n  B --&gt; E(Backfilling NA)\n  C --&gt; F[Saving Subset Data]\n  D --&gt; F[Saving Subset Data]\n  E --&gt; F[Saving Subset Data]\n\n\n\n\n\nflowchart LR\n  A[Importing Data] --&gt; B[Understanding and \\n cleaning the raw data]\n  B --&gt; C(Transforming columns)\n  B --&gt; D(Filtering Data)\n  B --&gt; E(Backfilling NA)\n  C --&gt; F[Saving Subset Data]\n  D --&gt; F[Saving Subset Data]\n  E --&gt; F[Saving Subset Data]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset Name\nCitywide Payroll Data (Fiscal Year)\n\n\nProvided by\nOffice of Payroll Administration (OPA)\n\n\nData Category\nCity Government\n\n\nFrequency of Updates\nAnnually\n\n\nDate Created\nOctober 31, 2015\n\n\nData Last Updated\nOctober 30, 2024\n\n\nDimensions\nRaw Data: 6,225,611 rows | 17 columns\nSubset Data: 804,630 rows | 17 columns\n\n\nEach row represents\nCity Employee Salary per Fiscal Year\n\n\nSource URL\nhttps://data.cityofnewyork.us/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImporting the data\nCreating the final subset data\n\n\n\nTo access the data, we can go directly to the URL:\n\n\nhttps://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/about_data\n\nFrom this URL, you can click the button ‚ÄòExport‚Äô, and then select Download File-CSV format (All data 6225611 rows). This will download a file of about 840MB. Remember, we are using the data Last Updated on October 30, 2024.\nThe file will be downloaded with the name: Citywide_Payroll_Data__Fiscal_Year__YYYYMMDD.csv\n\n\n(YYYYMMDD refers to the date that you downloaded the file)\n\nOnce the data was downloaded, it was added to a new folder inside the repository called ‚Äòdata_source‚Äô.\n\n\nCode\n# # import original data\n# payroll_data_source &lt;- read.csv(\"./data_source/Citywide_Payroll_Data__Fiscal_Year__20241111.csv\") \n# \n# # make a copy of original data for transformations\n# payroll_data &lt;- data.frame(payroll_data_source)\n# \n# # rename columns\n# names(payroll_data) &lt;- gsub(\"[\\\\.]+\", \"_\", tolower(names(payroll_data_source)))\n\n\n\n\n\n\n\nThe decision-making process for selecting a subset of the data and the detailed transformation the original dataset with 6,225,611 rows to our final dataset with 804,630 rows.\nTo generate the final subset use the code below:\n\n\nCode\n# payroll_data_fire_police &lt;-\n#   payroll_data |&gt; \n#   # clean agency name: \n#   mutate(agency_name_clean = trimws(gsub(\"#\\\\d+$\", \"\", agency_name))) |&gt; \n#   # clean location name: \n#   mutate(work_location_borough_clean = toupper(work_location_borough)) |&gt; \n# \n#   # filtering data:\n#   filter(agency_name_clean %in%  c(\"POLICE DEPARTMENT\",\"FIRE DEPARTMENT\")) |&gt; \n#   filter(work_location_borough_clean %in%   c(\"BRONX\", \"BROOKLYN\", \"MANHATTAN\", \"QUEENS\", \"RICHMOND\")) |&gt; \n#   filter(fiscal_year &gt;= \"2015\" & fiscal_year &lt;= \"2024\") |&gt; \n#   filter(pay_basis %in%   c(\"per Annum\", \"per Day\", \"per Hour\")) |&gt; \n#   \n#   # backfill payroll number after filtering\n#   mutate(\n#     payroll_number_clean = case_when(\n#       is.na(payroll_number) & agency_name_clean == \"FIRE DEPARTMENT\" ~ 57,\n#       is.na(payroll_number) & agency_name_clean == \"POLICE DEPARTMENT\" ~ 56,\n#       TRUE ~ payroll_number\n#     )) |&gt; \n#   \n#   # converting dates:\n#   mutate(agency_start_date_clean = mdy(agency_start_date)) |&gt; \n# \n#   # renaming clean columns to original names:\n#   mutate(\n#     agency_name = agency_name_clean,\n#     work_location_borough = work_location_borough_clean,\n#     payroll_number = payroll_number_clean,\n#     agency_start_date = agency_start_date_clean\n#   ) |&gt;\n#   \n#   # dropping clean columns\n#   dplyr::select(-agency_name_clean, \n#                 -work_location_borough_clean, \n#                 -payroll_number_clean,\n#                 -agency_start_date_clean)\n  \n\n\n# Please uncomment the CSV or the RDS method to save the subset data:\n\n# Save the data CSV\n# write.csv(payroll_data_fire_police, \"data_source/payroll_data_fire_police.csv\", row.names = FALSE)\n\n# Save the data RDS\n# saveRDS(payroll_data_fire_police, \"data_source/payroll_data_fire_police.rds\")\n\n# Read the data RDS\n# payroll_data_fire_police &lt;- readRDS(\"data_source/payroll_data_fire_police.rds\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "6¬† Appendix",
    "section": "",
    "text": "6.1 Creating the subset data\nIn this section, we will explore the decision-making process for selecting a subset of the data and the detailed transformation the original dataset with 6,225,611 rows to our final dataset with 804,630 rows.\nCode\nflowchart LR\n  A[Importing Data] --&gt; B[Understanding and \\n cleaning the raw data]\n  B --&gt; C(Transforming Columns)\n  B --&gt; D(Filtering Data)\n  B --&gt; E(Backfilling NA)\n  C --&gt; F[Saving Subset Data]\n  D --&gt; F[Saving Subset Data]\n  E --&gt; F[Saving Subset Data]\n\n\n\n\n\nflowchart LR\n  A[Importing Data] --&gt; B[Understanding and \\n cleaning the raw data]\n  B --&gt; C(Transforming Columns)\n  B --&gt; D(Filtering Data)\n  B --&gt; E(Backfilling NA)\n  C --&gt; F[Saving Subset Data]\n  D --&gt; F[Saving Subset Data]\n  E --&gt; F[Saving Subset Data]",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "appendix.html#importing-the-data",
    "href": "appendix.html#importing-the-data",
    "title": "6¬† Appendix",
    "section": "6.2 Importing the data",
    "text": "6.2 Importing the data\nTo access the data, we can go directly to the URL:\n\n\nhttps://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/about_data\n\nFrom this URL, you can click the button ‚ÄòExport‚Äô, and then select Download File-CSV format (All data 6225611 rows). This will download a file of about 840MB. Remember, we are using the data Last Updated on October 30, 2024.\nThe file will be downloaded with the name: Citywide_Payroll_Data__Fiscal_Year__YYYYMMDD.csv\n\n\n(YYYYMMDD refers to the date that you downloaded the file)\n\nOnce the data was downloaded, it was added to a new folder inside the repository called ‚Äòdata_source‚Äô.\n\n\nCode\n# import original data\npayroll_data_source &lt;- read.csv(\"./data_source/Citywide_Payroll_Data__Fiscal_Year__20241111.csv\") \n\n# make a copy of original data for transformations\npayroll_data &lt;- data.frame(payroll_data_source)\n\n# rename columns\nnames(payroll_data) &lt;- gsub(\"[\\\\.]+\", \"_\", tolower(names(payroll_data_source)))",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "appendix.html#understanding-and-cleaning-the-raw-data",
    "href": "appendix.html#understanding-and-cleaning-the-raw-data",
    "title": "6¬† Appendix",
    "section": "6.3 Understanding and cleaning the raw data",
    "text": "6.3 Understanding and cleaning the raw data\nStarting with the original data (6.22 million rows). This is quick summary of how many categories we have in each column:\n\n\nCode\npayroll_data |&gt; \n  summarise(\n    \"Number of Agencies\"     = n_distinct(agency_name),\n    \"Number of Titles\"       = n_distinct(title_description),\n    \"Number of Locations\"    = n_distinct(work_location_borough),\n    \"Number of Pay Basis\"    = n_distinct(pay_basis),\n    \"Number of Fiscal Years\" = n_distinct(fiscal_year)\n  ) |&gt; \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of Agencies\nNumber of Titles\nNumber of Locations\nNumber of Pay Basis\nNumber of Fiscal Years\n\n\n\n\n170\n1991\n23\n4\n11\n\n\n\n\n\n\n\n\n\n6.3.1 Agencies\nMany of the agencies in the raw data have the following format: AGENCY_NAME #NUMBER.\nExamples:\n\n\n\nBROOKLYN COMMUNITY BOARD #1\nBROOKLYN COMMUNITY BOARD #2\nBROOKLYN COMMUNITY BOARD #3\n\n\nWe will group Agency names by aggregating all agencies that have the same name, but different numbers. This will reduce overall number os agencies.\n\n\nCode\npayroll_data &lt;- \n  payroll_data |&gt; \n  mutate(agency_name_clean = trimws(gsub(\"#\\\\d+$\", \"\", agency_name)))\n\npayroll_data |&gt; \n  summarise(\n    \"Number of Agencies Before\" = n_distinct(agency_name),\n    \"Number of Agencies After\"  = n_distinct(agency_name_clean),\n  ) |&gt; \n  kable()\n\n\n\n\n\nNumber of Agencies Before\nNumber of Agencies After\n\n\n\n\n170\n116\n\n\n\n\n\n\nNow, let‚Äôs take a look at the top 10 Agencies:\n\n\nCode\npayroll_data_summary &lt;- payroll_data |&gt; \n  group_by(agency_name_clean) |&gt; \n  summarise(\n    Total_records = n()\n  ) |&gt; \n  arrange(desc(Total_records)) |&gt; \n  slice_head(n = 10)  \n\n\npayroll_data_summary |&gt; \n  kable(col.names = c(\"Agency\", \"Total Records\")) |&gt; \n  row_spec(which(payroll_data_summary$agency_name_clean == \"FIRE DEPARTMENT\"),   background = \"#f94144\", color = \"white\") |&gt; \n  row_spec(which(payroll_data_summary$agency_name_clean == \"POLICE DEPARTMENT\"), background = \"deepskyblue3\", color = \"white\")\n\n\n\n\n\nAgency\nTotal Records\n\n\n\n\nDEPT OF ED PEDAGOGICAL\n1207427\n\n\nDEPT OF ED PER SESSION TEACHER\n997983\n\n\nPOLICE DEPARTMENT\n612076\n\n\nDEPT OF ED PARA PROFESSIONALS\n412698\n\n\nBOARD OF ELECTION POLL WORKERS\n375001\n\n\nDEPT OF ED HRLY SUPPORT STAFF\n255501\n\n\nFIRE DEPARTMENT\n209272\n\n\nDEPARTMENT OF EDUCATION ADMIN\n181282\n\n\nDEPT OF PARKS & RECREATION\n170200\n\n\nHRA/DEPT OF SOCIAL SERVICES\n157963\n\n\n\n\n\n\n\n\n\n\n\n\n6.3.2 Work Location Borough\nWhen looking at the Work Location Borough, we see many recording with missing data (506,234 rows). We can also observe that the names of the locations are not standardized, some names are Uppercase and some are not (MANHATTAN vs Manhattan).\n\n\nCode\npayroll_data |&gt; \n  group_by(work_location_borough) |&gt; \n  summarise(\n    Total_records = n()\n  ) |&gt; \n  arrange(desc(Total_records)) |&gt; \n  slice_head(n = 10) |&gt; \n  kable(col.names = c(\"Locations\", \"Total Records\")) |&gt; \n  row_spec(which(payroll_data |&gt; \n                 group_by(work_location_borough) |&gt; \n                 summarise(Total_records = n()) |&gt; \n                 arrange(desc(Total_records)) |&gt; \n                 slice_head(n = 10) |&gt; \n                 pull(work_location_borough) %in% c(\"\",\"Bronx\", \"MANHATTAN\", \"Manhattan\")),   background = \"#fcefb4\", color = \"black\")\n\n\n\n\n\nLocations\nTotal Records\n\n\n\n\nMANHATTAN\n4077947\n\n\nQUEENS\n621225\n\n\nBROOKLYN\n523572\n\n\n\n506234\n\n\nBRONX\n286551\n\n\nOTHER\n116918\n\n\nRICHMOND\n77020\n\n\nWESTCHESTER\n5653\n\n\nULSTER\n3245\n\n\nManhattan\n1622\n\n\n\n\n\n\n\n\nOur first step here is to capitalize all the location names.\n\n\nCode\npayroll_data &lt;- payroll_data |&gt; \n  mutate(work_location_borough_clean = toupper(work_location_borough))\n\npayroll_data |&gt; \n  summarise(\n    \"Number of Locations Before\" = n_distinct(work_location_borough),\n    \"Number of Locations After\"  = n_distinct(work_location_borough_clean),\n  ) |&gt; \n  kable()\n\n\n\n\n\nNumber of Locations Before\nNumber of Locations After\n\n\n\n\n23\n19\n\n\n\n\n\n\nThe main 5 locations of this dataset are: BRONX, BROOKLYN, MANHATTAN, QUEENS, RICHMOND\nUsing the top 10 agencies that we found previously, we will keep all the agencies that have at least data for all 5 locations:\n\n\nCode\nrequired_boroughs &lt;- c(\"BRONX\", \"BROOKLYN\", \"MANHATTAN\", \"QUEENS\", \"RICHMOND\")\n\nagencies_present_in_required_boroughs &lt;-\n  payroll_data |&gt;\n  filter(work_location_borough_clean %in% required_boroughs) |&gt; \n  group_by(agency_name_clean) |&gt;  \n  summarise(\n    borough_count = n_distinct(work_location_borough_clean)  \n  ) |&gt;\n  filter(borough_count == length(required_boroughs)) |&gt; \n  filter(agency_name_clean %in% payroll_data_summary$agency_name_clean) |&gt; \n  pull(agency_name_clean)\n\n\npayroll_data_agencies_present_in_required_boroughs &lt;-\n  payroll_data |&gt; \n  filter(agency_name_clean %in% payroll_data_summary$agency_name_clean) |&gt; \n  filter(agency_name_clean %in% agencies_present_in_required_boroughs) |&gt; \n  group_by(agency_name_clean) |&gt; \n  summarise(\n    Total_records = n(),\n    \"Number of Locations\" = n_distinct(work_location_borough_clean)\n  ) |&gt; \n  arrange(desc(Total_records)) \n\npayroll_data_agencies_present_in_required_boroughs |&gt; \n  kable(col.names = c(\"Agency\", \"Total Records\", \"Number of Locations\")) |&gt; \n  row_spec(which(payroll_data_agencies_present_in_required_boroughs$agency_name_clean == \"FIRE DEPARTMENT\"),   background = \"#f94144\", color = \"white\") |&gt; \n  row_spec(which(payroll_data_agencies_present_in_required_boroughs$agency_name_clean == \"POLICE DEPARTMENT\"), background = \"deepskyblue3\", color = \"white\")\n\n\n\n\n\nAgency\nTotal Records\nNumber of Locations\n\n\n\n\nPOLICE DEPARTMENT\n612076\n5\n\n\nFIRE DEPARTMENT\n209272\n7\n\n\nDEPARTMENT OF EDUCATION ADMIN\n181282\n12\n\n\nDEPT OF PARKS & RECREATION\n170200\n7\n\n\nHRA/DEPT OF SOCIAL SERVICES\n157963\n8\n\n\n\n\n\n\n\n\nSince we are interested in the POLICE and FIRE departments, let‚Äôs take a closer look at the FIRE DEPARTMENT since it contains 7 locations. Based on these results, we have 1 record with location OTHER and 16555 with Blank location.\n\n\nCode\npayroll_data |&gt; \n  filter(agency_name_clean %in%  c(\"POLICE DEPARTMENT\",\"FIRE DEPARTMENT\")) |&gt; \n  filter(agency_name_clean %in% agencies_present_in_required_boroughs) |&gt; \n  group_by(agency_name_clean,work_location_borough_clean,fiscal_year) |&gt; \n  summarise(\n    Total_records = n(), .groups = 'drop'\n  ) |&gt; \n  arrange(agency_name_clean,work_location_borough_clean,fiscal_year) |&gt; \n  filter (!work_location_borough_clean %in% required_boroughs) |&gt; \n  kable(col.names = c(\"Agency\", \"Location\", \"Fiscal Year\", \"Total Records\"))\n\n\n\n\n\nAgency\nLocation\nFiscal Year\nTotal Records\n\n\n\n\nFIRE DEPARTMENT\n\n2014\n16555\n\n\nFIRE DEPARTMENT\nOTHER\n2022\n1\n\n\n\n\n\n\nThe final decision for location is to keep only data for the major 5 locations:\nBRONX, BROOKLYN, MANHATTAN, QUEENS, RICHMOND.\n\n\n\n\n\n6.3.3 Fiscal Year\nUsing only the FIRE and POLICE department, we can observe that we have no records for 2014 for the Police department. Please note that the 16555 in the FIRE department for 2014 are the same records with blank location we found before.\nThe final decision for Fiscal Year is to drop 2014 and keep only data from 2015 to 2024.\n\n\nCode\n# Create the pivot table\npivot_table_fiscal_year &lt;- payroll_data |&gt;\nfilter(agency_name_clean %in%  c(\n    \"POLICE DEPARTMENT\",\n    \"FIRE DEPARTMENT\"\n    )) |&gt; \n  group_by(fiscal_year, agency_name_clean) |&gt; \n  summarise(count = n(), .groups = 'drop') |&gt; \n  pivot_wider(\n    names_from = agency_name_clean,  \n    values_from = count,  \n    values_fill = list(count = 0) \n  )\n\npivot_table_fiscal_year |&gt;\n  kable(col.names = c(\"Fiscal Year\", \"FIRE DEPARTMENT\", \"POLICE DEPARTMENT\")) |&gt; \n  kable_styling() |&gt;\n  column_spec(3, background = ifelse(as.matrix(pivot_table_fiscal_year[, 3]) == 0, \"#fcefb4\", \"\"))\n\n\n\n\n\nFiscal Year\nFIRE DEPARTMENT\nPOLICE DEPARTMENT\n\n\n\n\n2014\n16555\n0\n\n\n2015\n17380\n59264\n\n\n2016\n19934\n65868\n\n\n2017\n18687\n62516\n\n\n2018\n18391\n59811\n\n\n2019\n18679\n59970\n\n\n2020\n19193\n60316\n\n\n2021\n19049\n59009\n\n\n2022\n20920\n60804\n\n\n2023\n19072\n58617\n\n\n2024\n21412\n65901\n\n\n\n\n\n\n\n\n\n\n\n\n6.3.4 Pay Basis\nBased on the different types of pay basis, we will drop the Prorated Annual as it is the category with the lowest amount of records and it only affects 1 job title (Chaplain).\nThe final decision for Pay Basis is to keep only data for the categories:\nper Annum, per Day, per Hour.\n\n\nCode\npayroll_data |&gt; \n  # filter(fiscal_year == \"2024\") |&gt;\n  filter(agency_name_clean %in%  c(\n    \"POLICE DEPARTMENT\",\n    \"FIRE DEPARTMENT\"\n    )) |&gt; \n  group_by(agency_name_clean,pay_basis) |&gt; \n  summarise(\n    Total_records = n(),\n    Count_of_titles = n_distinct(title_description)\n    , .groups = 'drop'\n  ) |&gt; \n  arrange(desc(Total_records)) |&gt;\n  kable(col.names = c(\"Agency\", \"Pay Basis\", \"Total Records\", \"Count of Titles\"))\n\n\n\n\n\nAgency\nPay Basis\nTotal Records\nCount of Titles\n\n\n\n\nPOLICE DEPARTMENT\nper Annum\n573429\n286\n\n\nFIRE DEPARTMENT\nper Annum\n203929\n199\n\n\nPOLICE DEPARTMENT\nper Hour\n32769\n29\n\n\nPOLICE DEPARTMENT\nper Day\n5794\n39\n\n\nFIRE DEPARTMENT\nper Day\n3934\n35\n\n\nFIRE DEPARTMENT\nper Hour\n1324\n47\n\n\nFIRE DEPARTMENT\nProrated Annual\n85\n1\n\n\nPOLICE DEPARTMENT\nProrated Annual\n84\n1\n\n\n\n\n\nCode\npayroll_data |&gt; \n  # filter(fiscal_year == \"2024\") |&gt;\n  filter(agency_name_clean %in%  c(\n    \"POLICE DEPARTMENT\",\n    \"FIRE DEPARTMENT\"\n    )) |&gt; \n  filter(pay_basis == \"Prorated Annual\") |&gt;\n  filter(title_description == \"CHAPLAIN\") |&gt; \n  group_by(agency_name_clean,pay_basis,title_description) |&gt; \n  summarise(\n    Total_records = n()\n    , .groups = 'drop'\n  ) |&gt; \n  arrange(agency_name_clean) |&gt;\n  kable(col.names = c(\"Agency\", \"Pay Basis\", \"Title\", \"Total Records\"))\n\n\n\n\n\nAgency\nPay Basis\nTitle\nTotal Records\n\n\n\n\nFIRE DEPARTMENT\nProrated Annual\nCHAPLAIN\n85\n\n\nPOLICE DEPARTMENT\nProrated Annual\nCHAPLAIN\n84\n\n\n\n\n\n\n\n\n\n\n6.3.5 Payroll Number\nFirst let‚Äôs start create a dataset filtered based on the criteria we discussed above:\n\n\n\nAgency (‚ÄúPOLICE DEPARTMENT‚Äù,‚ÄúFIRE DEPARTMENT‚Äù)\nLocation (‚ÄúBRONX‚Äù, ‚ÄúBROOKLYN‚Äù, ‚ÄúMANHATTAN‚Äù, ‚ÄúQUEENS‚Äù, ‚ÄúRICHMOND‚Äù),\nFiscal Year (2015-2024)\nPay Basis (‚Äúper Annum‚Äù, ‚Äúper Day‚Äù, ‚Äúper Hour‚Äù)\n\n\nFrom this dataset, we still have 243,601 NA records for the column `Payroll Number‚Äô. By doing a group by analysis per fiscal year, we can observe the NA are related to the years 2015, 2016, and 2017. So we will backfill those years with the proper payroll number code based on each agency. This way we will no longer have NA values in the new dataset.\n\n\nCode\npayroll_data_filtered &lt;- \n  payroll_data |&gt; \n  filter(agency_name_clean %in%  c(\"POLICE DEPARTMENT\",\"FIRE DEPARTMENT\")) |&gt; \n  filter(work_location_borough_clean %in%   c(\"BRONX\", \"BROOKLYN\", \"MANHATTAN\", \"QUEENS\", \"RICHMOND\")) |&gt; \n  filter(fiscal_year &gt; \"2014\") |&gt; \n  filter(pay_basis %in%   c(\"per Annum\", \"per Day\", \"per Hour\"))\n\n\n# Count NA values\nna_summary &lt;- payroll_data_filtered |&gt;\n  summarise(across(everything(), ~ sum(is.na(.)))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"NA Count\"\n  )\n\n# Count blank values\nblank_summary &lt;- payroll_data_filtered |&gt;\n  summarise(across(everything(), ~ sum(. == \"\", na.rm = TRUE))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Blank Count\"\n  )\n\n# Count zero values\nzero_summary &lt;- payroll_data_filtered |&gt;\n  summarise(across(everything(), ~ sum(. == 0, na.rm = TRUE))) |&gt;\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Zero Count\"\n  )\n\n\ncombined_summary &lt;- na_summary |&gt;\n  inner_join(blank_summary, by = \"Column\") |&gt;\n  inner_join(zero_summary, by = \"Column\")\n\n# combined_summary |&gt;\n#   filter(`NA Count` &gt; 0 | `Blank Count` &gt; 0 | `Zero Count` &gt; 0) |&gt; \n#   kable(col.names = c(\"Column\", \"NA Count\", \"Blank Count\", \"Zero Count\"))\n\nna_summary |&gt; \n  filter(`NA Count` &gt; 0) |&gt; \n  kable(col.names = c(\"Column\", \"NA Count\"))\n\n\n\n\n\nColumn\nNA Count\n\n\n\n\npayroll_number\n243601\n\n\n\n\n\n\n\nCode\npayroll_data_filtered_payroll &lt;- payroll_data_filtered |&gt; \n  group_by(agency_name_clean,payroll_number,fiscal_year) |&gt; \n  summarise(\n    Total_records = n()\n    ,.groups = \"drop\"\n  ) |&gt; \n  arrange(agency_name_clean,fiscal_year,desc(Total_records))\n\npayroll_data_filtered_payroll |&gt; \n  kable(col.names = c(\"Agency\", \"Payroll Number\", \"Fiscal Year\", \"Total Records\")) |&gt;\n  column_spec(2, background = ifelse(is.na(as.matrix(payroll_data_filtered_payroll[, 2])), \"#fcefb4\", \"\"))\n\n\n\n\n\nAgency\nPayroll Number\nFiscal Year\nTotal Records\n\n\n\n\nFIRE DEPARTMENT\nNA\n2015\n17372\n\n\nFIRE DEPARTMENT\nNA\n2016\n19926\n\n\nFIRE DEPARTMENT\nNA\n2017\n18679\n\n\nFIRE DEPARTMENT\n57\n2018\n18383\n\n\nFIRE DEPARTMENT\n57\n2019\n18671\n\n\nFIRE DEPARTMENT\n57\n2020\n19186\n\n\nFIRE DEPARTMENT\n57\n2021\n19042\n\n\nFIRE DEPARTMENT\n57\n2022\n20911\n\n\nFIRE DEPARTMENT\n57\n2023\n19063\n\n\nFIRE DEPARTMENT\n57\n2024\n21405\n\n\nPOLICE DEPARTMENT\nNA\n2015\n59257\n\n\nPOLICE DEPARTMENT\nNA\n2016\n65860\n\n\nPOLICE DEPARTMENT\nNA\n2017\n62507\n\n\nPOLICE DEPARTMENT\n56\n2018\n59802\n\n\nPOLICE DEPARTMENT\n56\n2019\n59961\n\n\nPOLICE DEPARTMENT\n56\n2020\n60308\n\n\nPOLICE DEPARTMENT\n56\n2021\n59001\n\n\nPOLICE DEPARTMENT\n56\n2022\n60795\n\n\nPOLICE DEPARTMENT\n56\n2023\n58608\n\n\nPOLICE DEPARTMENT\n56\n2024\n65893\n\n\n\n\n\n\n\n\n\nCode\n# Backfill NA values with the proper payroll number based on each agency\npayroll_data_filtered &lt;- \n  payroll_data_filtered |&gt;\n  mutate(\n    payroll_number_clean = case_when(\n      is.na(payroll_number) & agency_name_clean == \"FIRE DEPARTMENT\" ~ 57,\n      is.na(payroll_number) & agency_name_clean == \"POLICE DEPARTMENT\" ~ 56,\n      TRUE ~ payroll_number\n    )\n  ) \n\n\n\n\n\n\n\n6.3.6 Agency Start Date\nThe column agency_start_date is loaded as a character when we read the data for the first time. We will change the type to date using lubridate.\n\n\nCode\nlibrary(lubridate)\n\npayroll_data_filtered &lt;- \n  payroll_data_filtered |&gt; \n  mutate(agency_start_date_clean = mdy(agency_start_date))",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "appendix.html#saving-subset-data",
    "href": "appendix.html#saving-subset-data",
    "title": "6¬† Appendix",
    "section": "6.4 Saving Subset Data",
    "text": "6.4 Saving Subset Data\nWe will save the Final Subset Data into the folder /data_source/, so we can load it later inside results.qmd.\n\n\nCode\npayroll_data_fire_police &lt;-\n  payroll_data_filtered |&gt; \n\n  # renaming clean columns to original names:\n  mutate(\n    agency_name = agency_name_clean,\n    work_location_borough = work_location_borough_clean,\n    payroll_number = payroll_number_clean,\n    agency_start_date = agency_start_date_clean\n  ) |&gt;\n  \n  # dropping clean columns\n  dplyr::select(-agency_name_clean, \n                -work_location_borough_clean, \n                -payroll_number_clean,\n                -agency_start_date_clean)\n\n\n# Please uncomment the CSV or the RDS method to save the subset data:\n\n# Save the data CSV\n# write.csv(payroll_data_fire_police, \"data_source/payroll_data_fire_police.csv\", row.names = FALSE)\n\n# Save the data RDS\n# saveRDS(payroll_data_fire_police, \"data_source/payroll_data_fire_police.rds\")\n\n# Read the data RDS\n# payroll_data_fire_police &lt;- readRDS(\"data_source/payroll_data_fire_police.rds\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "appendix.html#final-subset-data-information",
    "href": "appendix.html#final-subset-data-information",
    "title": "6¬† Appendix",
    "section": "6.5 Final Subset Data Information",
    "text": "6.5 Final Subset Data Information\nBased on the analysis above, we will add a few filters to produce and clean our final dataset.\nFilters applied to the dataset:\n\n\n\n\n\n\nColumn Name\nFilter\n\n\n\n\nAgency Name\nFIRE DEPARTMENT, POLICE DEPARTMENT\n\n\nWork Location Borough\nBRONX, BROOKLYN, MANHATTAN, QUEENS, RICHMOND\n\n\nFiscal Year\nFrom 2015 to 2024\n\n\nPay Basis\nper Annum, per Day, per Hour\n\n\n\n\n\n\n\n\n\n\nCleaning data and Handling NAs:\n\n\n\n\n\n\nColumn Name\nNote\n\n\n\n\nAgency Name\nGroup agencies with similar names. Keep only FIRE and POLICE.\n\n\nWork Location Borough\nUppercase all names. Filtering data only for top 5 Boroughs.\n\n\nFiscal Year\n2014 had missing data for Police Department. 2014 will be removed.\n\n\nPay Basis\nKeeping only the top 3 Pay Basis.\n\n\nPayroll Number\nMissing NA values have been backfilled based on Agency Name.\n\n\nAgency Start Date\nConvert strings to date using lubridate.\n\n\n\n\n\n\n\n\n\n\nSize of Final subset Data\n\n\n\n\n\n\nDimensions\n804,630 rows and 17 columns\n\n\nEach row represents\nCity Employee Salary per Fiscal Year\n\n\n\n\n\n\n\nRecord count by Agency:\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr)\n\npayroll_data_fire_police |&gt; \n  group_by(agency_name) |&gt; \n  summarise(\n    Count = n()\n    , .groups = 'drop'\n  ) |&gt; \n  arrange(desc(Count)) |&gt;\n  mutate(Percentage = Count / sum(Count) * 100,\n         Label = paste(\n                       format(Count, big.mark = \",\"), \"\\n\", \" (\", sprintf(\"%.0f\", Percentage), \"%)\", sep = \"\")) |&gt; \nggplot(aes(x = \"\", y = Count, fill = agency_name)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  scale_fill_manual(name= 'Agency', values = c(\"#f94144\", \"deepskyblue3\")) +\n  # labs(title = \"Record Count by Department\") +\n  theme_void() +\n  geom_text(aes(label = Label), position = position_stack(vjust = 0.5), color = \"white\")\n\n\n\n\n\n\n\n\n\nOverall dataset Information:\n\n\n\n\n\n\n\n\n\n\n\nMetrics\nFire Deparmtnet\nPolice Department\n\n\n\n\nCount of Records\n192,638\n611,992\n\n\nFiscal Years\n10 years (2015-2024)\n10 years (2015-2024)\n\n\nAgency Start Date Range\n1968-04-22 to 2024-07-29\n1960-11-14 to 2049-10-16\n\n\nWork Location Borough\n5\n5\n\n\nTitle Description\n238\n335",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Appendix</span>"
    ]
  }
]